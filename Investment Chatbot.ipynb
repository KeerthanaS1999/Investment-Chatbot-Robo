{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investment Chatbot in Python (using NLTK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing NLTK Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) # for downloading packages\n",
    "# nltk.download('punkt') # first-time use only\n",
    "# nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chatbot.txt','r', encoding='utf8', errors ='ignore') as fin:\n",
    "    raw = fin.read()\n",
    "    raw = raw.lower() # converts to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is your name?', 'my name is robo and i will help you with your investment queries today.', 'invest\\nthere are many options to invest:\\n1. regional or investments banks\\n2. stocks\\nin which section would you like to invest?', 'money\\nthere are many options to invest:\\n1. regional or investments banks\\n2. stocks \\\\n\\nin which section would you like to invest?', 'where to put\\nthere are many options to invest:\\n1. regional or investments banks\\n2. stocks \\\\n\\nin which section would you like to invest?', 'loans\\nhousing,personal,educational.i recommend you to visit sbi banks for this.', 'investments banks\\nwell there are many such as: \\nubs\\nbarclays\\ndeutsche bank\\nhsbc\\nwells fargo\\n\\nregional banks\\nthere are many: \\nsbi\\nidbi\\nbob\\nkotak\\niob\\nicici\\nchoose any one to know more.', 'sbi\\nsbi offers loan at 10% interest.', 'iob\\niob offers loan at 9.50% interest.', 'idbi\\nkotak offers loan at 07% interest.', 'bob\\nbob offers loan at 11% interest.', 'kotak\\nkotak offers loan at 08% interest.', 'icici\\nicici offers a loan at 7.5% intrest.', 'stocks\\nwe have to companies to offer:\\nzoho\\nreliance\\nchoose any one to know more.', 'zoho\\nthe company zoho has a roi = 15%.', 'reliance\\nthe company reliance has a roi = 14%.']\n"
     ]
    }
   ],
   "source": [
    "# converts to list of sentences\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'your', 'name', '?', 'my', 'name', 'is', 'robo', 'and', 'i', 'will', 'help', 'you', 'with', 'your', 'investment', 'queries', 'today', '.', 'invest', 'there', 'are', 'many', 'options', 'to', 'invest', ':', '1.', 'regional', 'or', 'investments', 'banks', '2.', 'stocks', 'in', 'which', 'section', 'would', 'you', 'like', 'to', 'invest', '?', 'money', 'there', 'are', 'many', 'options', 'to', 'invest', ':', '1.', 'regional', 'or', 'investments', 'banks', '2.', 'stocks', '\\\\n', 'in', 'which', 'section', 'would', 'you', 'like', 'to', 'invest', '?', 'where', 'to', 'put', 'there', 'are', 'many', 'options', 'to', 'invest', ':', '1.', 'regional', 'or', 'investments', 'banks', '2.', 'stocks', '\\\\n', 'in', 'which', 'section', 'would', 'you', 'like', 'to', 'invest', '?', 'loans', 'housing', ',', 'personal', ',', 'educational.i', 'recommend', 'you', 'to', 'visit', 'sbi', 'banks', 'for', 'this', '.', 'investments', 'banks', 'well', 'there', 'are', 'many', 'such', 'as', ':', 'ubs', 'barclays', 'deutsche', 'bank', 'hsbc', 'wells', 'fargo', 'regional', 'banks', 'there', 'are', 'many', ':', 'sbi', 'idbi', 'bob', 'kotak', 'iob', 'icici', 'choose', 'any', 'one', 'to', 'know', 'more', '.', 'sbi', 'sbi', 'offers', 'loan', 'at', '10', '%', 'interest', '.', 'iob', 'iob', 'offers', 'loan', 'at', '9.50', '%', 'interest', '.', 'idbi', 'kotak', 'offers', 'loan', 'at', '07', '%', 'interest', '.', 'bob', 'bob', 'offers', 'loan', 'at', '11', '%', 'interest', '.', 'kotak', 'kotak', 'offers', 'loan', 'at', '08', '%', 'interest', '.', 'icici', 'icici', 'offers', 'a', 'loan', 'at', '7.5', '%', 'intrest', '.', 'stocks', 'we', 'have', 'to', 'companies', 'to', 'offer', ':', 'zoho', 'reliance', 'choose', 'any', 'one', 'to', 'know', 'more', '.', 'zoho', 'the', 'company', 'zoho', 'has', 'a', 'roi', '=', '15', '%', '.', 'reliance', 'the', 'company', 'reliance', 'has', 'a', 'roi', '=', '14', '%', '.']\n"
     ]
    }
   ],
   "source": [
    "# converts to list of words\n",
    "word_tokens = nltk.word_tokenize(raw)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Function called LemTokens is defined, which will take the tokens as input and return normalized tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Matching\n",
    "\n",
    "Next, we define a function for a greeting by the bot.\n",
    "i.e if a user’s input is a greeting, the bot shall return a greeting response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",\"Namaste\")\n",
    "GREETING_RESPONSES = [\"hi, how can i help you?\", \"hey\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a response from  chat bot for input questions, the concept of <b>document similarity</b> will be used. \n",
    "\n",
    "A function response which searches the user’s utterance for one or more known keywords and returns one of several possible responses. \n",
    "\n",
    "If it doesn’t find the input matching any of the keywords, it returns a response:” I am sorry! I don’t understand you”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines that chat bot will say while <b>starting and ending</b> a conversation depending upon user’s input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Robo. I will answer your queries about Investments. If you want to exit, type Bye!\n",
      "hello\n",
      "ROBO: hello\n",
      "loans\n",
      "ROBO: kotak offers loan at 07% interest.\n",
      "invest\n",
      "ROBO: there are many options to invest:\n",
      "1. regional or investments banks\n",
      "2. stocks\n",
      "in which section would you like to invest?\n",
      "regional banks\n",
      "ROBO: well there are many such as: \n",
      "ubs\n",
      "barclays\n",
      "deutsche bank\n",
      "hsbc\n",
      "wells fargo\n",
      "\n",
      "regional banks\n",
      "there are many: \n",
      "sbi\n",
      "idbi\n",
      "bob\n",
      "kotak\n",
      "iob\n",
      "icici\n",
      "choose any one to know more.\n",
      "sbi\n",
      "ROBO: sbi offers loan at 10% interest.\n",
      "icici\n",
      "ROBO: icici offers a loan at 7.5% intrest.\n",
      "idbi\n",
      "ROBO: kotak offers loan at 07% interest.\n",
      "stocks\n",
      "ROBO: we have to companies to offer:\n",
      "zoho\n",
      "reliance\n",
      "choose any one to know more.\n",
      "gdhj\n",
      "ROBO: I am sorry! I don't understand you\n",
      "zoho\n",
      "ROBO: the company zoho has a roi = 15%.\n",
      "reliance\n",
      "ROBO: the company reliance has a roi = 14%.\n",
      "money\n",
      "ROBO: there are many options to invest:\n",
      "1. regional or investments banks\n",
      "2. stocks \\n\n",
      "in which section would you like to invest?\n",
      "bye\n",
      "ROBO: Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries about Investments. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                res = response(user_response)\n",
    "                nlines = res.count('\\n')\n",
    "                if nlines > 0:\n",
    "                    res = res.split(\"\\n\",1)[1]\n",
    "                print(res)\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
